{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd968a06",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# # üè• HEART DISEASE PREDICTION PIPELINE\n",
    "# ## Complete ML System - From Data to Deployment\n",
    "# \n",
    "# **Objective:** Predict heart disease with 90%+ accuracy using patient medical data\n",
    "# **Algorithms:** SVM, Logistic Regression, Random Forest, XGBoost\n",
    "# **Author:** Your Name | **Date:** 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56eb83c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ## 1. Environment Setup\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# ## 1. Environment Setup\n",
    "\n",
    "# %%\n",
    "\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.config.settings import ProjectConfig\n",
    "from src.utils.logger import setup_logging\n",
    "from src.data.loader import DataLoader\n",
    "from src.data.preprocessor import DataPreprocessor\n",
    "from src.data.validator import DataValidator\n",
    "from src.eda.outlier_detector import detect_outliers_iqr\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config = ProjectConfig.load(\"heart\")\n",
    "logger = setup_logging(\"heart_pipeline\")\n",
    "logger.info(\"‚úÖ Heart disease prediction pipeline initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f800199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2. Data Loading & Validation\n",
    "\n",
    "loader = DataLoader(config)\n",
    "df = loader.load_heart_disease()\n",
    "validator = DataValidator(config)\n",
    "report = validator.generate_quality_report(df)\n",
    "print(f\"‚úÖ Dataset loaded: {df.shape[0]} patients, {df.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6987be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. Initial Data Inspection\n",
    "\n",
    "# %%\n",
    "print(\"üìä FIRST 5 ROWS:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nüìä DATA INFO:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nüìä BASIC STATISTICS:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Missing Values Analysis\n",
    "\n",
    "# %%\n",
    "missing = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing': df.isnull().sum().values,\n",
    "    'Percentage': (df.isnull().sum() / len(df) * 100).values\n",
    "}).sort_values('Percentage', ascending=False)\n",
    "\n",
    "print(\"üîç MISSING VALUES REPORT:\")\n",
    "display(missing[missing['Missing'] > 0])\n",
    "\n",
    "print(f\"\\n‚úÖ Total missing: {df.isnull().sum().sum()} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Duplicate Check\n",
    "\n",
    "# %%\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"üìä DUPLICATE ROWS: {duplicates}\")\n",
    "print(f\"Percentage: {(duplicates/len(df))*100:.2f}%\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"‚ö†Ô∏è Duplicates found - will remove during preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 6. Target Variable Distribution\n",
    "\n",
    "# %%\n",
    "target_dist = df['target'].value_counts()\n",
    "target_pct = df['target'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"üéØ TARGET DISTRIBUTION:\")\n",
    "print(f\"No Disease: {target_dist[0]} ({target_pct[0]:.1f}%)\")\n",
    "print(f\"Disease:    {target_dist[1]} ({target_pct[1]:.1f}%)\")\n",
    "\n",
    "if target_pct.min() < 30:\n",
    "    print(\"‚ö†Ô∏è Imbalanced dataset - will apply SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 7. Data Types Analysis\n",
    "\n",
    "# %%\n",
    "dtype_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Type': df.dtypes.values,\n",
    "    'Unique': [df[col].nunique() for col in df.columns]\n",
    "})\n",
    "\n",
    "print(\"üìä DATA TYPES:\")\n",
    "display(dtype_df)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\n‚úÖ Numeric columns: {len(numeric_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 8. Detailed Statistics\n",
    "\n",
    "# %%\n",
    "stats_df = df.describe().T\n",
    "stats_df['skew'] = df[numeric_cols].skew()\n",
    "stats_df['kurtosis'] = df[numeric_cols].kurtosis()\n",
    "\n",
    "print(\"üìà STATISTICAL SUMMARY:\")\n",
    "display(stats_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 9. Outlier Detection (IQR Method)\n",
    "\n",
    "\n",
    "outliers = detect_outliers_iqr(df, numeric_cols)\n",
    "outlier_df = pd.DataFrame(outliers).T.round(2)\n",
    "\n",
    "print(\"üîç OUTLIER REPORT:\")\n",
    "display(outlier_df)\n",
    "\n",
    "cols_with_outliers = outlier_df[outlier_df['percentage'] > 5].index.tolist()\n",
    "print(f\"\\n‚ö†Ô∏è Columns with >5% outliers: {cols_with_outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 10. Outlier Detection using IQR Method\n",
    "\n",
    "# %%\n",
    "# Detect outliers using IQR method\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'target' in numerical_cols:\n",
    "    numerical_cols.remove('target')\n",
    "\n",
    "outlier_info_iqr = detect_outliers_iqr(df, numerical_cols)\n",
    "\n",
    "print(\"üîç OUTLIER DETECTION (IQR METHOD):\")\n",
    "print(\"=\"*70)\n",
    "outlier_df = pd.DataFrame(outlier_info_iqr).T\n",
    "display(outlier_df.round(2))\n",
    "\n",
    "# Highlight columns with significant outliers\n",
    "significant_outliers = outlier_df[outlier_df['outlier_percentage'] > 5]\n",
    "if len(significant_outliers) > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Columns with >5% outliers:\")\n",
    "    for col in significant_outliers.index:\n",
    "        print(f\"   - {col}: {significant_outliers.loc[col, 'outlier_percentage']:.2f}% outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 10. Feature Correlation with Target\n",
    "\n",
    "# %%\n",
    "correlations = df[numeric_cols].corr()['target'].drop('target').sort_values(ascending=False)\n",
    "\n",
    "print(\"üìä FEATURE CORRELATION WITH TARGET:\")\n",
    "for feat, corr in correlations.items():\n",
    "    print(f\"{feat:10}: {corr:+.3f}\")\n",
    "\n",
    "top_features = correlations.head(5).index.tolist()\n",
    "print(f\"\\n‚úÖ Top 5 features: {top_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 11. Target Distribution Visualization\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.bar(['No Disease', 'Disease'], target_dist.values, color=['#4ECDC4', '#FF6B6B'])\n",
    "ax1.set_title('Target Distribution', fontweight='bold')\n",
    "for i, v in enumerate(target_dist.values):\n",
    "    ax1.text(i, v+5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "ax2.pie(target_dist.values, labels=['No Disease', 'Disease'], \n",
    "        autopct='%1.1f%%', colors=['#4ECDC4', '#FF6B6B'])\n",
    "ax2.set_title('Target Distribution (%)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 12. Age Distribution by Target\n",
    "\n",
    "# %%\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for target in [0, 1]:\n",
    "    subset = df[df['target'] == target]['age']\n",
    "    ax1.hist(subset, alpha=0.7, label=f'Target {target}', bins=20)\n",
    "ax1.set_xlabel('Age')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Age Distribution by Target', fontweight='bold')\n",
    "ax1.legend(['No Disease', 'Disease'])\n",
    "\n",
    "df.boxplot(column='age', by='target', ax=ax2)\n",
    "ax2.set_title('Age Boxplot by Target', fontweight='bold')\n",
    "ax2.set_xlabel('Target (0=No Disease, 1=Disease)')\n",
    "\n",
    "plt.suptitle('Age Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 13. Chest Pain Type Analysis\n",
    "\n",
    "# %%\n",
    "cp_cross = pd.crosstab(df['cp'], df['target'])\n",
    "cp_cross.columns = ['No Disease', 'Disease']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "cp_cross.plot(kind='bar', stacked=True, ax=ax, color=['#4ECDC4', '#FF6B6B'])\n",
    "ax.set_title('Chest Pain Type vs Disease', fontweight='bold', fontsize=14)\n",
    "ax.set_xlabel('Chest Pain Type (0-3)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend(['No Disease', 'Disease'])\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 14. Maximum Heart Rate Analysis\n",
    "\n",
    "# %%\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "df.boxplot(column='thalach', by='target', ax=ax1)\n",
    "ax1.set_title('Max Heart Rate by Target', fontweight='bold')\n",
    "ax1.set_ylabel('Max Heart Rate')\n",
    "\n",
    "for target in [0, 1]:\n",
    "    subset = df[df['target'] == target]['thalach']\n",
    "    ax2.hist(subset, alpha=0.7, label=f'Target {target}', bins=20)\n",
    "ax2.set_xlabel('Max Heart Rate')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Heart Rate Distribution', fontweight='bold')\n",
    "ax2.legend(['No Disease', 'Disease'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c362fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 15. ST Depression (Oldpeak) Analysis\n",
    "\n",
    "# %%\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "df.boxplot(column='oldpeak', by='target', ax=ax1)\n",
    "ax1.set_title('ST Depression by Target', fontweight='bold')\n",
    "ax1.set_ylabel('Oldpeak')\n",
    "\n",
    "for target in [0, 1]:\n",
    "    subset = df[df['target'] == target]['oldpeak']\n",
    "    ax2.hist(subset, alpha=0.7, label=f'Target {target}', bins=20)\n",
    "ax2.set_xlabel('Oldpeak')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('ST Depression Distribution', fontweight='bold')\n",
    "ax2.legend(['No Disease', 'Disease'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 16. Correlation Heatmap\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "corr = df.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "            center=0, square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 17. Gender Analysis\n",
    "\n",
    "# %%\n",
    "gender_cross = pd.crosstab(df['sex'], df['target'])\n",
    "gender_cross.index = ['Female', 'Male']\n",
    "gender_cross.columns = ['No Disease', 'Disease']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "gender_cross.plot(kind='bar', ax=ax, color=['#4ECDC4', '#FF6B6B'])\n",
    "ax.set_title('Gender vs Heart Disease', fontweight='bold', fontsize=14)\n",
    "ax.set_xlabel('Gender')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend(['No Disease', 'Disease'])\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 18. Feature Importance (Correlation Based)\n",
    "\n",
    "# %%\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlations.sort_values().plot(kind='barh', color='#2E86AB')\n",
    "plt.title('Feature Importance - Correlation with Target', fontweight='bold', fontsize=14)\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 19. Data Preprocessing\n",
    "\n",
    "# %%\n",
    "\n",
    "preprocessor = DataPreprocessor(config)\n",
    "X_train, X_test, y_train, y_test = preprocessor.prepare_dataset(df)\n",
    "\n",
    "print(f\"‚úÖ Training set: {X_train.shape}\")\n",
    "print(f\"‚úÖ Testing set:  {X_test.shape}\")\n",
    "print(f\"‚úÖ Classes balanced: {len(np.unique(y_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 20. Training: Logistic Regression\n",
    "\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_proba = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"‚úÖ Logistic Regression trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 21. Training: Support Vector Machine\n",
    "\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "svm_proba = svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"‚úÖ SVM trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 24. Model Comparison: Accuracy\n",
    "\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest', 'XGBoost']\n",
    "predictions = [lr_pred, svm_pred, rf_pred, xgb_pred]\n",
    "accuracies = [accuracy_score(y_test, pred) for pred in predictions]\n",
    "\n",
    "for model, acc in zip(models, accuracies):\n",
    "    print(f\"{model:20}: {acc:.4f}\")\n",
    "\n",
    "best_acc_idx = np.argmax(accuracies)\n",
    "print(f\"\\nüèÜ Best model: {models[best_acc_idx]} with accuracy {accuracies[best_acc_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 25. Model Comparison: Precision\n",
    "\n",
    "\n",
    "precisions = [precision_score(y_test, pred) for pred in predictions]\n",
    "\n",
    "for model, prec in zip(models, precisions):\n",
    "    print(f\"{model:20}: {prec:.4f}\")\n",
    "\n",
    "best_prec_idx = np.argmax(precisions)\n",
    "print(f\"\\nüèÜ Best model: {models[best_prec_idx]} with precision {precisions[best_prec_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 26. Model Comparison: Recall\n",
    "\n",
    "recalls = [recall_score(y_test, pred) for pred in predictions]\n",
    "\n",
    "for model, rec in zip(models, recalls):\n",
    "    print(f\"{model:20}: {rec:.4f}\")\n",
    "\n",
    "best_rec_idx = np.argmax(recalls)\n",
    "print(f\"\\nüèÜ Best model: {models[best_rec_idx]} with recall {recalls[best_rec_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 27. Model Comparison: F1 Score\n",
    "\n",
    "\n",
    "f1_scores = [f1_score(y_test, pred) for pred in predictions]\n",
    "\n",
    "for model, f1 in zip(models, f1_scores):\n",
    "    print(f\"{model:20}: {f1:.4f}\")\n",
    "\n",
    "best_f1_idx = np.argmax(f1_scores)\n",
    "best_model = models[best_f1_idx]\n",
    "best_f1 = f1_scores[best_f1_idx]\n",
    "print(f\"\\nüèÜ Best model: {best_model} with F1 score {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 28. Model Comparison: ROC-AUC\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "probabilities = [lr_proba, svm_proba, rf_proba, xgb_proba]\n",
    "roc_aucs = [roc_auc_score(y_test, proba) for proba in probabilities]\n",
    "\n",
    "for model, auc in zip(models, roc_aucs):\n",
    "    print(f\"{model:20}: {auc:.4f}\")\n",
    "\n",
    "best_auc_idx = np.argmax(roc_aucs)\n",
    "print(f\"\\nüèÜ Best model: {models[best_auc_idx]} with ROC-AUC {roc_aucs[best_auc_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 29. Complete Results Summary\n",
    "\n",
    "# %%\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1-Score': f1_scores,\n",
    "    'ROC-AUC': roc_aucs\n",
    "}).round(4)\n",
    "\n",
    "print(\"üìä MODEL COMPARISON SUMMARY:\")\n",
    "display(results_df)\n",
    "\n",
    "best_overall = results_df.loc[results_df['F1-Score'].idxmax()]\n",
    "print(f\"\\nüèÜ OVERALL BEST MODEL: {best_overall['Model']}\")\n",
    "print(f\"   F1-Score: {best_overall['F1-Score']:.4f}\")\n",
    "print(f\"   Accuracy: {best_overall['Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 30. Confusion Matrix (Best Model)\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "best_pred = [lr_pred, svm_pred, rf_pred, xgb_pred][best_f1_idx]\n",
    "cm = confusion_matrix(y_test, best_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Disease', 'Disease'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix - {best_model}', fontweight='bold', fontsize=14)\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"True Negatives:  {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives:  {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 31. ROC Curves Comparison\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model, proba, name in zip(models, probabilities, models):\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison', fontweight='bold', fontsize=14)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a9154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 32. Feature Importance (Best Model)\n",
    "\n",
    "# %%\n",
    "if best_model in ['Random Forest', 'XGBoost']:\n",
    "    best_model_obj = [rf_model, xgb_model][models.index(best_model)-2]\n",
    "    importances = best_model_obj.feature_importances_\n",
    "    \n",
    "    feat_imp = pd.DataFrame({\n",
    "        'Feature': df.drop('target', axis=1).columns,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(feat_imp['Feature'], feat_imp['Importance'], color='#2E86AB')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Feature Importance - {best_model}', fontweight='bold', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 5 Most Important Features:\")\n",
    "    for i, row in feat_imp.tail(5).iterrows():\n",
    "        print(f\"   {row['Feature']}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 33. Precision-Recall Curve\n",
    "\n",
    "# %%\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model, proba, name in zip(models, probabilities, models):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, proba)\n",
    "    plt.plot(recall, precision, label=name, linewidth=2)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves', fontweight='bold', fontsize=14)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 34. Learning Curve Analysis\n",
    "\n",
    "# %%\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "if best_model in ['Random Forest', 'XGBoost']:\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        best_model_obj, X_train, y_train, cv=5, n_jobs=-1,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "    )\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, 'o-', label='Training score', color='blue')\n",
    "    plt.plot(train_sizes, test_mean, 'o-', label='Cross-validation score', color='red')\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f'Learning Curve - {best_model}', fontweight='bold', fontsize=14)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b502e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 35. Save Model for Deployment\n",
    "\n",
    "\n",
    "best_model_obj = [lr_model, svm_model, rf_model, xgb_model][best_f1_idx]\n",
    "model_path = f'../models/heart_{best_model.lower().replace(\" \", \"_\")}_v1.0.0.pkl'\n",
    "joblib.dump(best_model_obj, model_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved: {model_path}\")\n",
    "print(f\"üìÖ Saved at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38573b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 36. Save Preprocessor & Feature Names\n",
    "\n",
    "# %%\n",
    "joblib.dump(preprocessor.scaler, '../models/heart_scaler.pkl')\n",
    "joblib.dump(df.drop('target', axis=1).columns.tolist(), '../models/heart_features.pkl')\n",
    "\n",
    "print(\"‚úÖ Preprocessor saved\")\n",
    "print(\"‚úÖ Feature names saved\")\n",
    "print(f\"üìä Features: {len(df.columns)-1} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 37. Model Metadata\n",
    "\n",
    "# %%\n",
    "metadata = {\n",
    "    'model_name': best_model,\n",
    "    'version': '1.0.0',\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'dataset_shape': df.shape,\n",
    "    'features': df.drop('target', axis=1).columns.tolist(),\n",
    "    'metrics': {\n",
    "        'accuracy': float(best_overall['Accuracy']),\n",
    "        'precision': float(best_overall['Precision']),\n",
    "        'recall': float(best_overall['Recall']),\n",
    "        'f1_score': float(best_overall['F1-Score']),\n",
    "        'roc_auc': float(best_overall['ROC-AUC'])\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../models/heart_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Model metadata saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bbd1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 38. Test Single Prediction\n",
    "\n",
    "# %%\n",
    "sample = X_test[0].reshape(1, -1)\n",
    "pred = best_model_obj.predict(sample)[0]\n",
    "proba = best_model_obj.predict_proba(sample)[0]\n",
    "\n",
    "print(\"üîç SINGLE PREDICTION TEST:\")\n",
    "print(f\"Actual:    {y_test.iloc[0]}\")\n",
    "print(f\"Predicted: {pred}\")\n",
    "print(f\"Probability: No Disease: {proba[0]:.3f}, Disease: {proba[1]:.3f}\")\n",
    "print(f\"Risk Level: {'HIGH' if pred == 1 else 'LOW'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 39. Export Results to CSV\n",
    "\n",
    "# %%\n",
    "results_df.to_csv('../reports/heart_model_comparison.csv', index=False)\n",
    "print(\"‚úÖ Results exported to reports/heart_model_comparison.csv\")\n",
    "\n",
    "results_df.style.background_gradient(cmap='Blues', subset=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb743b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 40. Pipeline Complete - Final Summary\n",
    "\n",
    "# %%\n",
    "summary = f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                    PIPELINE COMPLETED SUCCESSFULLY               ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë  Dataset:        Heart Disease                                    ‚ïë\n",
    "‚ïë  Samples:        {df.shape[0]:,} patients                         ‚ïë\n",
    "‚ïë  Features:       {df.shape[1]-1}                                  ‚ïë\n",
    "‚ïë  Best Model:     {best_model}                                     ‚ïë\n",
    "‚ïë  F1-Score:       {best_overall['F1-Score']:.4f}                   ‚ïë\n",
    "‚ïë  Accuracy:       {best_overall['Accuracy']:.4f}                   ‚ïë\n",
    "‚ïë  ROC-AUC:        {best_overall['ROC-AUC']:.4f}                    ‚ïë\n",
    "‚ïë  Model Saved:    models/heart_{best_model.lower().replace(' ', '_')}_v1.0.0.pkl  ‚ïë\n",
    "‚ïë  Reports:        reports/heart_model_comparison.csv               ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "with open('../reports/heart_summary.txt', 'w') as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 41. Environment Information\n",
    "\n",
    "# %%\n",
    "import sklearn\n",
    "import xgboost\n",
    "import imblearn\n",
    "\n",
    "print(\"üîß ENVIRONMENT:\")\n",
    "print(f\"Python:        {sys.version.split()[0]}\")\n",
    "print(f\"Pandas:        {pd.__version__}\")\n",
    "print(f\"NumPy:         {np.__version__}\")\n",
    "print(f\"Scikit-learn:  {sklearn.__version__}\")\n",
    "print(f\"XGBoost:       {xgboost.__version__}\")\n",
    "print(f\"Imbalanced:    {imblearn.__version__}\")\n",
    "print(f\"Joblib:        {joblib.__version__}\")\n",
    "\n",
    "print(\"\\n‚úÖ All systems ready for deployment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 42. Next Steps - Deployment\n",
    "\n",
    "# %%\n",
    "print(\"\"\"\n",
    "üöÄ READY FOR DEPLOYMENT:\n",
    "\n",
    "1. Start API server:\n",
    "   $ uvicorn api.main:app --reload\n",
    "\n",
    "2. Access API documentation:\n",
    "   http://localhost:8000/docs\n",
    "\n",
    "3. Make predictions via API:\n",
    "   curl -X POST http://localhost:8000/predict/heart \\\\\n",
    "        -H \"Content-Type: application/json\" \\\\\n",
    "        -d '{\"age\": 55, \"sex\": 1, \"cp\": 0, \"trestbps\": 140, ...}'\n",
    "\n",
    "4. Run with Docker:\n",
    "   $ docker build -t heart-model .\n",
    "   $ docker run -p 8000:8000 heart-model\n",
    "\n",
    "5. Monitor performance:\n",
    "   $ python scripts/monitor.py\n",
    "\n",
    "üéâ CONGRATULATIONS! Your winning project is complete!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
